{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca71bd2e",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32743adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36571bf",
   "metadata": {},
   "source": [
    "## 2. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2e2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tickers = {\n",
    "    'S&P 500': '^GSPC',\n",
    "    'FTSE 100': '^FTSE',\n",
    "    'Nikkei 225': '^N225',\n",
    "    'Gold ETF': 'GLD',\n",
    "    'US Treasury Bonds': 'TLT'\n",
    "}\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2020-12-31'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98849d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download data for each ticker\n",
    "data = {}\n",
    "for asset, ticker in tickers.items():\n",
    "    data[asset] = yf.download(ticker, start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d0866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price             Close         High          Low         Open      Volume  \\\n",
      "Ticker            ^GSPC        ^GSPC        ^GSPC        ^GSPC       ^GSPC   \n",
      "Date                                                                         \n",
      "2020-12-23  3690.010010  3711.239990  3689.280029  3693.419922  3779160000   \n",
      "2020-12-24  3703.060059  3703.820068  3689.320068  3694.030029  1883780000   \n",
      "2020-12-28  3735.360107  3740.510010  3723.030029  3723.030029  3535460000   \n",
      "2020-12-29  3727.040039  3756.120117  3723.310059  3750.010010  3393290000   \n",
      "2020-12-30  3732.040039  3744.629883  3730.209961  3736.189941  3154850000   \n",
      "\n",
      "Price      Log Return  \n",
      "Ticker                 \n",
      "Date                   \n",
      "2020-12-23   0.000746  \n",
      "2020-12-24   0.003530  \n",
      "2020-12-28   0.008685  \n",
      "2020-12-29  -0.002230  \n",
      "2020-12-30   0.001341  \n"
     ]
    }
   ],
   "source": [
    "# Function to calculate log returns\n",
    "def calculate_log_returns(df):\n",
    "    df['Log Return'] = df['Close'].pct_change().apply(lambda x: np.log(1 + x))\n",
    "    return df\n",
    "\n",
    "# Calculate log returns for each asset\n",
    "for asset in data:\n",
    "    data[asset] = calculate_log_returns(data[asset])\n",
    "\n",
    "print(data['S&P 500'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "603fa72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price             Close         High          Low         Open      Volume  \\\n",
      "Ticker            ^GSPC        ^GSPC        ^GSPC        ^GSPC       ^GSPC   \n",
      "Date                                                                         \n",
      "2020-12-23  3690.010010  3711.239990  3689.280029  3693.419922  3779160000   \n",
      "2020-12-24  3703.060059  3703.820068  3689.320068  3694.030029  1883780000   \n",
      "2020-12-28  3735.360107  3740.510010  3723.030029  3723.030029  3535460000   \n",
      "2020-12-29  3727.040039  3756.120117  3723.310059  3750.010010  3393290000   \n",
      "2020-12-30  3732.040039  3744.629883  3730.209961  3736.189941  3154850000   \n",
      "\n",
      "Price      Log Return     5-day MA    21-day MA  \n",
      "Ticker                                           \n",
      "Date                                             \n",
      "2020-12-23   0.000746  3700.815967  3674.680466  \n",
      "2020-12-24   0.003530  3696.931982  3677.901902  \n",
      "2020-12-28   0.008685  3702.122021  3682.935721  \n",
      "2020-12-29  -0.002230  3708.546045  3687.159052  \n",
      "2020-12-30   0.001341  3717.502051  3692.416678  \n"
     ]
    }
   ],
   "source": [
    "# Add 5-day and 21-day moving averages for each asset\n",
    "for asset, df in data.items():\n",
    "    df['5-day MA'] = df['Close'].rolling(window=5).mean()\n",
    "    df['21-day MA'] = df['Close'].rolling(window=21).mean()\n",
    "\n",
    "\n",
    "print(data['S&P 500'].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae7afd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price             Close         High          Low         Open      Volume  \\\n",
      "Ticker            ^GSPC        ^GSPC        ^GSPC        ^GSPC       ^GSPC   \n",
      "Date                                                                         \n",
      "2020-12-23  3690.010010  3711.239990  3689.280029  3693.419922  3779160000   \n",
      "2020-12-24  3703.060059  3703.820068  3689.320068  3694.030029  1883780000   \n",
      "2020-12-28  3735.360107  3740.510010  3723.030029  3723.030029  3535460000   \n",
      "2020-12-29  3727.040039  3756.120117  3723.310059  3750.010010  3393290000   \n",
      "2020-12-30  3732.040039  3744.629883  3730.209961  3736.189941  3154850000   \n",
      "\n",
      "Price      Log Return     5-day MA    21-day MA Volatility  \n",
      "Ticker                                                      \n",
      "Date                                                        \n",
      "2020-12-23   0.000746  3700.815967  3674.680466   0.006239  \n",
      "2020-12-24   0.003530  3696.931982  3677.901902   0.005307  \n",
      "2020-12-28   0.008685  3702.122021  3682.935721   0.005537  \n",
      "2020-12-29  -0.002230  3708.546045  3687.159052   0.005586  \n",
      "2020-12-30   0.001341  3717.502051  3692.416678   0.005428  \n"
     ]
    }
   ],
   "source": [
    "# Add 21-day rolling volatility for each asset\n",
    "for asset, df in data.items():\n",
    "    df['Volatility'] = df['Log Return'].rolling(window=21).std()\n",
    "\n",
    "\n",
    "print(data['S&P 500'].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad3b555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price             Close         High          Low         Open      Volume  \\\n",
      "Ticker            ^GSPC        ^GSPC        ^GSPC        ^GSPC       ^GSPC   \n",
      "Date                                                                         \n",
      "2020-12-23  3690.010010  3711.239990  3689.280029  3693.419922  3779160000   \n",
      "2020-12-24  3703.060059  3703.820068  3689.320068  3694.030029  1883780000   \n",
      "2020-12-28  3735.360107  3740.510010  3723.030029  3723.030029  3535460000   \n",
      "2020-12-29  3727.040039  3756.120117  3723.310059  3750.010010  3393290000   \n",
      "2020-12-30  3732.040039  3744.629883  3730.209961  3736.189941  3154850000   \n",
      "\n",
      "Price      Log Return     5-day MA    21-day MA Volatility  \n",
      "Ticker                                                      \n",
      "Date                                                        \n",
      "2020-12-23   0.000746  3700.815967  3674.680466   0.006239  \n",
      "2020-12-24   0.003530  3696.931982  3677.901902   0.005307  \n",
      "2020-12-28   0.008685  3702.122021  3682.935721   0.005537  \n",
      "2020-12-29  -0.002230  3708.546045  3687.159052   0.005586  \n",
      "2020-12-30   0.001341  3717.502051  3692.416678   0.005428  \n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values \n",
    "for asset in data:\n",
    "    data[asset].dropna(inplace=True)\n",
    "\n",
    "\n",
    "print(data['S&P 500'].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12abf8",
   "metadata": {},
   "source": [
    "## 3. Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a76672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            S&P 500 Log Return  S&P 500 5-day MA  S&P 500 21-day MA  \\\n",
      "Date                                                                  \n",
      "2020-12-24            0.003530       3696.931982        3677.901902   \n",
      "2020-12-25                 NaN               NaN                NaN   \n",
      "2020-12-28            0.008685       3702.122021        3682.935721   \n",
      "2020-12-29           -0.002230       3708.546045        3687.159052   \n",
      "2020-12-30            0.001341       3717.502051        3692.416678   \n",
      "\n",
      "            S&P 500 Volatility  FTSE 100 Log Return  FTSE 100 5-day MA  \\\n",
      "Date                                                                     \n",
      "2020-12-24            0.005307             0.000969        6498.900000   \n",
      "2020-12-25                 NaN                  NaN                NaN   \n",
      "2020-12-28            0.005537                  NaN                NaN   \n",
      "2020-12-29            0.005586             0.015353        6509.220020   \n",
      "2020-12-30            0.005428            -0.007129        6514.539941   \n",
      "\n",
      "            FTSE 100 21-day MA  FTSE 100 Volatility  Nikkei 225 Log Return  \\\n",
      "Date                                                                         \n",
      "2020-12-24         6486.285668             0.008887               0.005398   \n",
      "2020-12-25                 NaN                  NaN              -0.000440   \n",
      "2020-12-28                 NaN                  NaN               0.007379   \n",
      "2020-12-29         6496.361863             0.009299               0.026245   \n",
      "2020-12-30         6505.547573             0.009404              -0.004507   \n",
      "\n",
      "            Nikkei 225 5-day MA  Nikkei 225 21-day MA  Nikkei 225 Volatility  \\\n",
      "Date                                                                           \n",
      "2020-12-24         26621.467969          26671.317987               0.006221   \n",
      "2020-12-25         26600.111719          26676.998884               0.005916   \n",
      "2020-12-28         26628.033594          26686.966425               0.006067   \n",
      "2020-12-29         26854.385547          26740.991722               0.008001   \n",
      "2020-12-30         27038.261719          26772.259859               0.007681   \n",
      "\n",
      "            Gold ETF Log Return  Gold ETF 5-day MA  Gold ETF 21-day MA  \\\n",
      "Date                                                                     \n",
      "2020-12-24             0.003977         175.762003          173.058095   \n",
      "2020-12-25                  NaN                NaN                 NaN   \n",
      "2020-12-28            -0.003636         175.616003          173.353334   \n",
      "2020-12-29             0.003636         175.710004          173.760954   \n",
      "2020-12-30             0.007626         176.352002          174.286192   \n",
      "\n",
      "            Gold ETF Volatility  US Treasury Bonds Log Return  \\\n",
      "Date                                                            \n",
      "2020-12-24             0.009141                      0.003949   \n",
      "2020-12-25                  NaN                           NaN   \n",
      "2020-12-28             0.009207                      0.000445   \n",
      "2020-12-29             0.008798                     -0.001271   \n",
      "2020-12-30             0.008613                      0.002161   \n",
      "\n",
      "            US Treasury Bonds 5-day MA  US Treasury Bonds 21-day MA  \\\n",
      "Date                                                                  \n",
      "2020-12-24                  137.769461                   138.123672   \n",
      "2020-12-25                         NaN                          NaN   \n",
      "2020-12-28                  137.950220                   138.082168   \n",
      "2020-12-29                  137.987088                   137.968093   \n",
      "2020-12-30                  137.941452                   137.876561   \n",
      "\n",
      "            US Treasury Bonds Volatility  \n",
      "Date                                      \n",
      "2020-12-24                      0.007137  \n",
      "2020-12-25                           NaN  \n",
      "2020-12-28                      0.007114  \n",
      "2020-12-29                      0.006739  \n",
      "2020-12-30                      0.006769  \n"
     ]
    }
   ],
   "source": [
    "# Combine data for all assets into a single DataFrame\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "for asset, df in data.items():\n",
    "    asset_data = df[['Log Return', '5-day MA', '21-day MA', 'Volatility']]\n",
    "    asset_data.columns = [f'{asset} Log Return', f'{asset} 5-day MA', f'{asset} 21-day MA', f'{asset} Volatility']\n",
    "    merged_data = pd.concat([merged_data, asset_data], axis=1)\n",
    "\n",
    "\n",
    "print(merged_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e69a907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset in data:\n",
    "    merged_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7057a52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P 500 Log Return</th>\n",
       "      <th>S&amp;P 500 5-day MA</th>\n",
       "      <th>S&amp;P 500 21-day MA</th>\n",
       "      <th>S&amp;P 500 Volatility</th>\n",
       "      <th>FTSE 100 Log Return</th>\n",
       "      <th>FTSE 100 5-day MA</th>\n",
       "      <th>FTSE 100 21-day MA</th>\n",
       "      <th>FTSE 100 Volatility</th>\n",
       "      <th>Nikkei 225 Log Return</th>\n",
       "      <th>Nikkei 225 5-day MA</th>\n",
       "      <th>Nikkei 225 21-day MA</th>\n",
       "      <th>Nikkei 225 Volatility</th>\n",
       "      <th>Gold ETF Log Return</th>\n",
       "      <th>Gold ETF 5-day MA</th>\n",
       "      <th>Gold ETF 21-day MA</th>\n",
       "      <th>Gold ETF Volatility</th>\n",
       "      <th>US Treasury Bonds Log Return</th>\n",
       "      <th>US Treasury Bonds 5-day MA</th>\n",
       "      <th>US Treasury Bonds 21-day MA</th>\n",
       "      <th>US Treasury Bonds Volatility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-03</th>\n",
       "      <td>-0.005489</td>\n",
       "      <td>1089.637988</td>\n",
       "      <td>1119.278570</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>-0.005713</td>\n",
       "      <td>5223.620020</td>\n",
       "      <td>5380.666690</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>10318.553906</td>\n",
       "      <td>10614.118583</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>107.723999</td>\n",
       "      <td>109.350476</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>-0.011663</td>\n",
       "      <td>59.371735</td>\n",
       "      <td>58.909332</td>\n",
       "      <td>0.008266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-04</th>\n",
       "      <td>-0.031636</td>\n",
       "      <td>1085.353979</td>\n",
       "      <td>1115.782854</td>\n",
       "      <td>0.012106</td>\n",
       "      <td>-0.021921</td>\n",
       "      <td>5222.339941</td>\n",
       "      <td>5362.061919</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>10306.891992</td>\n",
       "      <td>10598.601935</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>-0.040649</td>\n",
       "      <td>107.301999</td>\n",
       "      <td>109.096667</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>59.448825</td>\n",
       "      <td>58.962280</td>\n",
       "      <td>0.008830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>0.002893</td>\n",
       "      <td>1083.817969</td>\n",
       "      <td>1112.404279</td>\n",
       "      <td>0.012153</td>\n",
       "      <td>-0.015373</td>\n",
       "      <td>5196.819922</td>\n",
       "      <td>5339.880952</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>-0.029286</td>\n",
       "      <td>10278.701953</td>\n",
       "      <td>10566.489537</td>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>107.045999</td>\n",
       "      <td>108.771428</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>59.448164</td>\n",
       "      <td>59.058796</td>\n",
       "      <td>0.008194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-08</th>\n",
       "      <td>-0.008903</td>\n",
       "      <td>1077.327979</td>\n",
       "      <td>1108.359044</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>5165.799902</td>\n",
       "      <td>5318.838077</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>-0.010522</td>\n",
       "      <td>10228.062109</td>\n",
       "      <td>10531.735259</td>\n",
       "      <td>0.013819</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>106.184000</td>\n",
       "      <td>108.448571</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>59.571834</td>\n",
       "      <td>59.154398</td>\n",
       "      <td>0.008194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-09</th>\n",
       "      <td>0.012956</td>\n",
       "      <td>1070.767993</td>\n",
       "      <td>1104.813331</td>\n",
       "      <td>0.012568</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>5131.499902</td>\n",
       "      <td>5298.538063</td>\n",
       "      <td>0.009813</td>\n",
       "      <td>-0.001903</td>\n",
       "      <td>10140.424219</td>\n",
       "      <td>10490.524786</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>0.013082</td>\n",
       "      <td>105.440001</td>\n",
       "      <td>108.164762</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>-0.010039</td>\n",
       "      <td>59.541898</td>\n",
       "      <td>59.222720</td>\n",
       "      <td>0.008574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            S&P 500 Log Return  S&P 500 5-day MA  S&P 500 21-day MA  \\\n",
       "Date                                                                  \n",
       "2010-02-03           -0.005489       1089.637988        1119.278570   \n",
       "2010-02-04           -0.031636       1085.353979        1115.782854   \n",
       "2010-02-05            0.002893       1083.817969        1112.404279   \n",
       "2010-02-08           -0.008903       1077.327979        1108.359044   \n",
       "2010-02-09            0.012956       1070.767993        1104.813331   \n",
       "\n",
       "            S&P 500 Volatility  FTSE 100 Log Return  FTSE 100 5-day MA  \\\n",
       "Date                                                                     \n",
       "2010-02-03            0.010256            -0.005713        5223.620020   \n",
       "2010-02-04            0.012106            -0.021921        5222.339941   \n",
       "2010-02-05            0.012153            -0.015373        5196.819922   \n",
       "2010-02-08            0.012104             0.006185        5165.799902   \n",
       "2010-02-09            0.012568             0.003822        5131.499902   \n",
       "\n",
       "            FTSE 100 21-day MA  FTSE 100 Volatility  Nikkei 225 Log Return  \\\n",
       "Date                                                                         \n",
       "2010-02-03         5380.666690             0.008208               0.003200   \n",
       "2010-02-04         5362.061919             0.009191              -0.004658   \n",
       "2010-02-05         5339.880952             0.009518              -0.029286   \n",
       "2010-02-08         5318.838077             0.009715              -0.010522   \n",
       "2010-02-09         5298.538063             0.009813              -0.001903   \n",
       "\n",
       "            Nikkei 225 5-day MA  Nikkei 225 21-day MA  Nikkei 225 Volatility  \\\n",
       "Date                                                                           \n",
       "2010-02-03         10318.553906          10614.118583               0.012431   \n",
       "2010-02-04         10306.891992          10598.601935               0.012424   \n",
       "2010-02-05         10278.701953          10566.489537               0.013726   \n",
       "2010-02-08         10228.062109          10531.735259               0.013819   \n",
       "2010-02-09         10140.424219          10490.524786               0.013437   \n",
       "\n",
       "            Gold ETF Log Return  Gold ETF 5-day MA  Gold ETF 21-day MA  \\\n",
       "Date                                                                     \n",
       "2010-02-03            -0.003948         107.723999          109.350476   \n",
       "2010-02-04            -0.040649         107.301999          109.096667   \n",
       "2010-02-05             0.002966         107.045999          108.771428   \n",
       "2010-02-08            -0.006133         106.184000          108.448571   \n",
       "2010-02-09             0.013082         105.440001          108.164762   \n",
       "\n",
       "            Gold ETF Volatility  US Treasury Bonds Log Return  \\\n",
       "Date                                                            \n",
       "2010-02-03             0.011520                     -0.011663   \n",
       "2010-02-04             0.014478                      0.015703   \n",
       "2010-02-05             0.013895                      0.002177   \n",
       "2010-02-08             0.013894                      0.001304   \n",
       "2010-02-09             0.014236                     -0.010039   \n",
       "\n",
       "            US Treasury Bonds 5-day MA  US Treasury Bonds 21-day MA  \\\n",
       "Date                                                                  \n",
       "2010-02-03                   59.371735                    58.909332   \n",
       "2010-02-04                   59.448825                    58.962280   \n",
       "2010-02-05                   59.448164                    59.058796   \n",
       "2010-02-08                   59.571834                    59.154398   \n",
       "2010-02-09                   59.541898                    59.222720   \n",
       "\n",
       "            US Treasury Bonds Volatility  \n",
       "Date                                      \n",
       "2010-02-03                      0.008266  \n",
       "2010-02-04                      0.008830  \n",
       "2010-02-05                      0.008194  \n",
       "2010-02-08                      0.008194  \n",
       "2010-02-09                      0.008574  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d227a7",
   "metadata": {},
   "source": [
    "## 4. Feature & Target Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c186e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Drop the last row from both the features and target to align their lengths\n",
    "features = merged_data.values[:-1]  # Drop the last row of features to match target length\n",
    "target = merged_data['S&P 500 Log Return'].shift(-1).dropna().values  # Shift target and drop NaN values\n",
    "\n",
    "# Ensure that both features and target arrays have the same length after dropping the last row\n",
    "assert len(features) == len(target), f\"Features and target length mismatch: {len(features)} != {len(target)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3201e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2028, 1, 20) (508, 1, 20)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Reshape the data for LSTM input (samples, timesteps, features)\n",
    "X_train_lstm = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Check the shape of the data\n",
    "print(X_train_lstm.shape, X_test_lstm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6353727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_lstm, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_lstm, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca2589",
   "metadata": {},
   "source": [
    "## 5. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbfe4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 2/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2764e-04 - val_loss: 0.0020\n",
      "Epoch 3/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5398e-04 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.8195e-04 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.6113e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4396e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2758e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3814e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1124e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1491e-04 - val_loss: 0.0011\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4251e-04 \n",
      "LSTM Model Loss: 0.0010999138467013836\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Build the LSTM model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "# Add LSTM layer (units = 50, return_sequences=False to output only the final time step)\n",
    "model_lstm.add(LSTM(units=50, return_sequences=False, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "\n",
    "# Add Dense layer for prediction\n",
    "model_lstm.add(Dense(units=1))  # Predicting a single value (next day's return)\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the LSTM model\n",
    "history_lstm = model_lstm.fit(X_train_lstm, y_train, epochs=10, batch_size=32, validation_data=(X_test_lstm, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "lstm_loss = model_lstm.evaluate(X_test_lstm, y_test)\n",
    "print(\"LSTM Model Loss:\", lstm_loss)\n",
    "\n",
    "y_pred_lstm = model_lstm.predict(X_test_lstm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffdf648",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac9a5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_layers, output_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # Transformer block (No target input, only source)\n",
    "        self.transformer = nn.Transformer(d_model=input_dim, nhead=num_heads, num_encoder_layers=num_layers)\n",
    "        \n",
    "        # Fully connected layer for output\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is of shape (batch_size, seq_len, input_dim)\n",
    "        x = x.permute(1, 0, 2)  # Change shape to (seq_len, batch_size, input_dim) for Transformer\n",
    "        \n",
    "        # Apply the Transformer\n",
    "        # Since we don't need a target (tgt), we will use the same input `x` as the input to the Transformer\n",
    "        x = self.transformer(x, x)  # Pass the same tensor as both source and target\n",
    "        \n",
    "        # Pooling across the sequence length (mean pooling)\n",
    "        x = x.mean(dim=0)  # Pooling across the sequence length\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model_transformer = TransformerModel(input_dim=X_train.shape[1], num_heads=4, num_layers=2, output_dim=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_transformer.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6924d59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.004986262880265713\n",
      "Epoch [2/50], Loss: 0.004976753145456314\n",
      "Epoch [3/50], Loss: 0.004759818781167269\n",
      "Epoch [4/50], Loss: 0.004259653855115175\n",
      "Epoch [5/50], Loss: 0.0037758592516183853\n",
      "Epoch [6/50], Loss: 0.003530823392793536\n",
      "Epoch [7/50], Loss: 0.003348270198330283\n",
      "Epoch [8/50], Loss: 0.003415740327909589\n",
      "Epoch [9/50], Loss: 0.003178624203428626\n",
      "Epoch [10/50], Loss: 0.00316948676481843\n",
      "Epoch [11/50], Loss: 0.002968250075355172\n",
      "Epoch [12/50], Loss: 0.002656942931935191\n",
      "Epoch [13/50], Loss: 0.002847072435542941\n",
      "Epoch [14/50], Loss: 0.00249610492028296\n",
      "Epoch [15/50], Loss: 0.0022535184398293495\n",
      "Epoch [16/50], Loss: 0.0024818822275847197\n",
      "Epoch [17/50], Loss: 0.0025071275886148214\n",
      "Epoch [18/50], Loss: 0.0025469474494457245\n",
      "Epoch [19/50], Loss: 0.002558793406933546\n",
      "Epoch [20/50], Loss: 0.002368098823353648\n",
      "Epoch [21/50], Loss: 0.0023074785713106394\n",
      "Epoch [22/50], Loss: 0.0021353887859731913\n",
      "Epoch [23/50], Loss: 0.0020737480372190475\n",
      "Epoch [24/50], Loss: 0.0019116778858006\n",
      "Epoch [25/50], Loss: 0.0018031913787126541\n",
      "Epoch [26/50], Loss: 0.002005584305152297\n",
      "Epoch [27/50], Loss: 0.0018230840796604753\n",
      "Epoch [28/50], Loss: 0.0018414462683722377\n",
      "Epoch [29/50], Loss: 0.00171185121871531\n",
      "Epoch [30/50], Loss: 0.0018381488043814898\n",
      "Epoch [31/50], Loss: 0.0017297681188210845\n",
      "Epoch [32/50], Loss: 0.0017568765906617045\n",
      "Epoch [33/50], Loss: 0.0017636126140132546\n",
      "Epoch [34/50], Loss: 0.0016663065180182457\n",
      "Epoch [35/50], Loss: 0.001595351379364729\n",
      "Epoch [36/50], Loss: 0.001610303996130824\n",
      "Epoch [37/50], Loss: 0.0015249931020662189\n",
      "Epoch [38/50], Loss: 0.0015661184443160892\n",
      "Epoch [39/50], Loss: 0.0014582956209778786\n",
      "Epoch [40/50], Loss: 0.0014417622005566955\n",
      "Epoch [41/50], Loss: 0.001409959397278726\n",
      "Epoch [42/50], Loss: 0.0014377790503203869\n",
      "Epoch [43/50], Loss: 0.001357400557026267\n",
      "Epoch [44/50], Loss: 0.0013763663591817021\n",
      "Epoch [45/50], Loss: 0.001399260014295578\n",
      "Epoch [46/50], Loss: 0.001361046452075243\n",
      "Epoch [47/50], Loss: 0.0013382500037550926\n",
      "Epoch [48/50], Loss: 0.0012329258024692535\n",
      "Epoch [49/50], Loss: 0.0012712355237454176\n",
      "Epoch [50/50], Loss: 0.001309234299696982\n",
      "Transformer Model Loss: 0.00028883854974992573\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model_transformer.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model_transformer(X_train_tensor)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_train_tensor.view(-1, 1))\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Evaluate the Transformer model on test data\n",
    "model_transformer.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_transformer = model_transformer(X_test_tensor)\n",
    "    transformer_loss = criterion(y_pred_transformer, y_test_tensor.view(-1, 1))\n",
    "\n",
    "print(\"Transformer Model Loss:\", transformer_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12d01057",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e65437",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "485761dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_dim': [64, 128],\n",
    "    'num_layers': [2, 3],\n",
    "    'dropout': [0.1, 0.2],\n",
    "    'learning_rate': [0.0003, 0.0005],\n",
    "    'epochs': [50],\n",
    "    'batch_size': [32]\n",
    "}\n",
    "\n",
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "best_params = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b3661ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 64, 'learning_rate': 0.0003, 'num_layers': 2}\n",
      "Epoch [10/50], Loss: 0.000110\n",
      "Early stopping at epoch 19 with loss 0.00010595958883641288\n",
      "Test MSE: 0.000327, R²: -0.1994, MAE: 0.011673\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 64, 'learning_rate': 0.0003, 'num_layers': 3}\n",
      "Epoch [10/50], Loss: 0.000233\n",
      "Epoch [20/50], Loss: 0.000095\n",
      "Early stopping at epoch 28 with loss 0.00011972255742875859\n",
      "Test MSE: 0.000283, R²: -0.0384, MAE: 0.010589\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 64, 'learning_rate': 0.0005, 'num_layers': 2}\n",
      "Epoch [10/50], Loss: 0.001491\n",
      "Epoch [20/50], Loss: 0.000275\n",
      "Epoch [30/50], Loss: 0.000233\n",
      "Epoch [40/50], Loss: 0.000140\n",
      "Epoch [50/50], Loss: 0.000110\n",
      "Test MSE: 0.000686, R²: -1.5185, MAE: 0.019447\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 64, 'learning_rate': 0.0005, 'num_layers': 3}\n",
      "Epoch [10/50], Loss: 0.000096\n",
      "Epoch [20/50], Loss: 0.000168\n",
      "Early stopping at epoch 21 with loss 0.0001585844438523054\n",
      "Test MSE: 0.000307, R²: -0.1265, MAE: 0.010996\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0003, 'num_layers': 2}\n",
      "Epoch [10/50], Loss: 0.002427\n",
      "Epoch [20/50], Loss: 0.000576\n",
      "Epoch [30/50], Loss: 0.000184\n",
      "Epoch [40/50], Loss: 0.000173\n",
      "Epoch [50/50], Loss: 0.000106\n",
      "Test MSE: 0.000434, R²: -0.5929, MAE: 0.013570\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0003, 'num_layers': 3}\n",
      "Epoch [10/50], Loss: 0.004040\n",
      "Epoch [20/50], Loss: 0.001180\n",
      "Epoch [30/50], Loss: 0.000146\n",
      "Epoch [40/50], Loss: 0.000195\n",
      "Early stopping at epoch 42 with loss 0.00019125397375319153\n",
      "Test MSE: 0.000401, R²: -0.4705, MAE: 0.013702\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0005, 'num_layers': 2}\n",
      "Epoch [10/50], Loss: 0.000136\n",
      "Epoch [20/50], Loss: 0.000105\n",
      "Epoch [30/50], Loss: 0.000091\n",
      "Epoch [40/50], Loss: 0.000089\n",
      "Epoch [50/50], Loss: 0.000087\n",
      "Test MSE: 0.000264, R²: 0.0317, MAE: 0.009611\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0005, 'num_layers': 3}\n",
      "Epoch [10/50], Loss: 0.000098\n",
      "Epoch [20/50], Loss: 0.000089\n",
      "Epoch [30/50], Loss: 0.000087\n",
      "Epoch [40/50], Loss: 0.000087\n",
      "Early stopping at epoch 42 with loss 8.69373106979765e-05\n",
      "Test MSE: 0.000267, R²: 0.0205, MAE: 0.009634\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.2, 'epochs': 50, 'hidden_dim': 64, 'learning_rate': 0.0003, 'num_layers': 2}\n",
      "Epoch [10/50], Loss: 0.008527\n",
      "Epoch [20/50], Loss: 0.005273\n",
      "Epoch [30/50], Loss: 0.002874\n",
      "Epoch [40/50], Loss: 0.001334\n",
      "Epoch [50/50], Loss: 0.000595\n",
      "Test MSE: 0.003317, R²: -11.1710, MAE: 0.052585\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.2, 'epochs': 50, 'hidden_dim': 64, 'learning_rate': 0.0003, 'num_layers': 3}\n",
      "Epoch [10/50], Loss: 0.004197\n",
      "Epoch [20/50], Loss: 0.001939\n",
      "Epoch [30/50], Loss: 0.000626\n",
      "Epoch [40/50], Loss: 0.000157\n",
      "Epoch [50/50], Loss: 0.000127\n",
      "Test MSE: 0.000337, R²: -0.2358, MAE: 0.011780\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.2, 'epochs': 50, 'hidden_dim': 64, 'learning_rate': 0.0005, 'num_layers': 2}\n",
      "Epoch [10/50], Loss: 0.001102\n",
      "Epoch [20/50], Loss: 0.000175\n",
      "Epoch [30/50], Loss: 0.000206\n",
      "Early stopping at epoch 32 with loss 0.00019566225819289684\n",
      "Test MSE: 0.000410, R²: -0.5046, MAE: 0.013494\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.2, 'epochs': 50, 'hidden_dim': 64, 'learning_rate': 0.0005, 'num_layers': 3}\n",
      "Epoch [10/50], Loss: 0.000180\n",
      "Epoch [20/50], Loss: 0.000181\n",
      "Early stopping at epoch 23 with loss 0.00017764112271834165\n",
      "Test MSE: 0.000303, R²: -0.1122, MAE: 0.011178\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.2, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0003, 'num_layers': 2}\n",
      "Epoch [10/50], Loss: 0.000232\n",
      "Epoch [20/50], Loss: 0.000165\n",
      "Early stopping at epoch 25 with loss 0.00014727175584994256\n",
      "Test MSE: 0.000382, R²: -0.4001, MAE: 0.013669\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.2, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0003, 'num_layers': 3}\n",
      "Epoch [10/50], Loss: 0.001304\n",
      "Epoch [20/50], Loss: 0.000151\n",
      "Epoch [30/50], Loss: 0.000172\n",
      "Early stopping at epoch 33 with loss 0.00017618027050048113\n",
      "Test MSE: 0.000288, R²: -0.0553, MAE: 0.010956\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.2, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0005, 'num_layers': 2}\n",
      "Epoch [10/50], Loss: 0.000251\n",
      "Epoch [20/50], Loss: 0.000255\n",
      "Early stopping at epoch 23 with loss 0.00020701026369351894\n",
      "Test MSE: 0.000348, R²: -0.2767, MAE: 0.013048\n",
      "\n",
      "Training with: {'batch_size': 32, 'dropout': 0.2, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0005, 'num_layers': 3}\n",
      "Epoch [10/50], Loss: 0.000186\n",
      "Early stopping at epoch 15 with loss 9.595573646947742e-05\n",
      "Test MSE: 0.000273, R²: -0.0013, MAE: 0.009842\n"
     ]
    }
   ],
   "source": [
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nTraining with: {params}\")\n",
    "    model = LSTMModel(input_dim=X_train_lstm.shape[2],\n",
    "                      hidden_dim=params['hidden_dim'],\n",
    "                      num_layers=params['num_layers'],\n",
    "                      dropout=params['dropout'])\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience, patience_counter = 10, 0\n",
    "\n",
    "    for epoch in range(params['epochs']):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train_tensor)\n",
    "        loss = criterion(y_pred, y_train_tensor.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} with loss {loss.item()}\")\n",
    "            break\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{params['epochs']}], Loss: {loss.item():.6f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test_tensor).cpu().numpy().flatten()\n",
    "        mse = mean_squared_error(y_test, y_pred_test)\n",
    "        r2 = r2_score(y_test, y_pred_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        print(f\"Test MSE: {mse:.6f}, R²: {r2:.4f}, MAE: {mae:.6f}\")\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007249a6",
   "metadata": {},
   "source": [
    "## 7. Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d2b662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Best Model Performance:\n",
      "Best MSE: 0.000264\n",
      "Best Params: {'batch_size': 32, 'dropout': 0.1, 'epochs': 50, 'hidden_dim': 128, 'learning_rate': 0.0005, 'num_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🏆 Best Model Performance:\")\n",
    "print(f\"Best MSE: {best_mse:.6f}\")\n",
    "print(f\"Best Params: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e05ce15",
   "metadata": {},
   "source": [
    "### Single Asset Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "596a1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).cpu().numpy().flatten()\n",
    "    \n",
    "    # Store predictions\n",
    "date_index = merged_data.index[-len(y_pred):]\n",
    "predictions[asset] = pd.Series(y_pred, index=date_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c6de9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gold ETF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-15</th>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-16</th>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-17</th>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-18</th>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19</th>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>-0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>-0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>-0.000459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>-0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>-0.000413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gold ETF\n",
       "Date                \n",
       "2018-10-15  0.000942\n",
       "2018-10-16  0.001510\n",
       "2018-10-17  0.000816\n",
       "2018-10-18  0.001325\n",
       "2018-10-19  0.001534\n",
       "...              ...\n",
       "2020-12-21 -0.000552\n",
       "2020-12-23 -0.000739\n",
       "2020-12-24 -0.000459\n",
       "2020-12-29 -0.000646\n",
       "2020-12-30 -0.000413\n",
       "\n",
       "[508 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_returns = pd.DataFrame(predictions)\n",
    "predicted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7300464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-Variance weight strategy\n",
    "expected_returns = predicted_returns.mean()\n",
    "volatility = predicted_returns.std()\n",
    "weights = expected_returns / volatility\n",
    "weights /= weights.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a77fc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate portfolio\n",
    "daily_returns = predicted_returns @ weights\n",
    "portfolio_nav = (1 + daily_returns).cumprod()\n",
    "\n",
    "# Evaluation functions\n",
    "def sharpe_ratio(returns, risk_free_rate=0.0):\n",
    "    return (returns.mean() - risk_free_rate) / returns.std()\n",
    "\n",
    "def max_drawdown(nav):\n",
    "    peak = nav.cummax()\n",
    "    return ((nav - peak) / peak).min()\n",
    "\n",
    "def annualized_return(returns, freq=252):\n",
    "    return (1 + returns.mean())**freq - 1\n",
    "\n",
    "def annualized_volatility(returns, freq=252):\n",
    "    return returns.std() * np.sqrt(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d066532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio Evaluation\n",
      "Sharpe Ratio: 0.3180\n",
      "Max Drawdown: -12.21%\n",
      "Annualized Return: 7.34%\n",
      "Annualized Volatility: 1.40%\n",
      "\n",
      "Asset Weights Used:\n",
      "US Treasury Bonds    1.0\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final metrics\n",
    "print(\"Portfolio Evaluation\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio(daily_returns):.4f}\")\n",
    "print(f\"Max Drawdown: {max_drawdown(portfolio_nav):.2%}\")\n",
    "print(f\"Annualized Return: {annualized_return(daily_returns):.2%}\")\n",
    "print(f\"Annualized Volatility: {annualized_volatility(daily_returns):.2%}\")\n",
    "print(\"\\nAsset Weights Used:\")\n",
    "print(weights.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708991f",
   "metadata": {},
   "source": [
    "### Multi Asset Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "826b7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "assets = ['S&P 500', 'FTSE 100', 'Gold ETF']\n",
    "for asset in assets:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor).cpu().numpy().flatten()\n",
    "        \n",
    "        # Store predictions\n",
    "    date_index = merged_data.index[-len(y_pred):]\n",
    "    predictions[asset] = pd.Series(y_pred, index=date_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f23fa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P 500</th>\n",
       "      <th>FTSE 100</th>\n",
       "      <th>Gold ETF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-15</th>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-16</th>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-17</th>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-18</th>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19</th>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>-0.000552</td>\n",
       "      <td>-0.000552</td>\n",
       "      <td>-0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>-0.000739</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>-0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>-0.000646</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>-0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.000413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             S&P 500  FTSE 100  Gold ETF\n",
       "Date                                    \n",
       "2018-10-15  0.000942  0.000942  0.000942\n",
       "2018-10-16  0.001510  0.001510  0.001510\n",
       "2018-10-17  0.000816  0.000816  0.000816\n",
       "2018-10-18  0.001325  0.001325  0.001325\n",
       "2018-10-19  0.001534  0.001534  0.001534\n",
       "...              ...       ...       ...\n",
       "2020-12-21 -0.000552 -0.000552 -0.000552\n",
       "2020-12-23 -0.000739 -0.000739 -0.000739\n",
       "2020-12-24 -0.000459 -0.000459 -0.000459\n",
       "2020-12-29 -0.000646 -0.000646 -0.000646\n",
       "2020-12-30 -0.000413 -0.000413 -0.000413\n",
       "\n",
       "[508 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_returns = pd.DataFrame(predictions)\n",
    "predicted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55807076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-Variance weight strategy\n",
    "expected_returns = predicted_returns.mean()\n",
    "volatility = predicted_returns.std()\n",
    "weights = expected_returns / volatility\n",
    "weights /= weights.sum()\n",
    "daily_returns = predicted_returns @ weights\n",
    "portfolio_nav = (1 + daily_returns).cumprod()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6fa2e61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio Evaluation\n",
      "Sharpe Ratio: 0.3180\n",
      "Max Drawdown: -12.21%\n",
      "Annualized Return: 7.34%\n",
      "Annualized Volatility: 1.40%\n",
      "\n",
      "Asset Weights Used:\n",
      "S&P 500     0.3333\n",
      "FTSE 100    0.3333\n",
      "Gold ETF    0.3333\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Final metrics\n",
    "print(\"Portfolio Evaluation\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio(daily_returns):.4f}\")\n",
    "print(f\"Max Drawdown: {max_drawdown(portfolio_nav):.2%}\")\n",
    "print(f\"Annualized Return: {annualized_return(daily_returns):.2%}\")\n",
    "print(f\"Annualized Volatility: {annualized_volatility(daily_returns):.2%}\")\n",
    "print(\"\\nAsset Weights Used:\")\n",
    "print(weights.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116bb3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
